TrueNAS Performance Optimization Report
Generated: {{ ansible_date_time.iso8601 }}
Host: {{ ansible_hostname }}
Configured by: Ansible Performance Role

===========================================
ZFS ARC Memory Configuration
===========================================
ARC Maximum Memory: {{ (zfs_arc_settings.arc_max | int / 1024 / 1024 / 1024) | round(2) }}GB
ARC Minimum Memory: {{ (zfs_arc_settings.arc_min | int / 1024 / 1024 / 1024) | round(2) }}GB

Configuration Details:
- vfs.zfs.arc_max = {{ zfs_arc_settings.arc_max }}
- vfs.zfs.arc_min = {{ zfs_arc_settings.arc_min }}

===========================================
CPU Governor Configuration
===========================================
CPU Governor: {{ cpu_governor_settings.governor }}
Hardware P-state Control: Enabled

Configuration Details:
- dev.cpu.0.freq_levels = {{ cpu_governor_settings.governor }}
- machdep.hwpstate_pkg_ctrl = 1

===========================================
Network Buffer Optimizations
===========================================
Maximum Receive Buffer: {{ (network_buffer_settings.net_core_rmem_max | int / 1024 / 1024) | round(2) }}MB
Maximum Send Buffer: {{ (network_buffer_settings.net_core_wmem_max | int / 1024 / 1024) | round(2) }}MB
TCP Congestion Control: {{ network_buffer_settings.net_ipv4_tcp_congestion_control }}
Network Device Backlog: {{ network_buffer_settings.net_core_netdev_max_backlog }}

Configuration Details:
- net.core.rmem_max = {{ network_buffer_settings.net_core_rmem_max }}
- net.core.wmem_max = {{ network_buffer_settings.net_core_wmem_max }}
- net.core.rmem_default = {{ network_buffer_settings.net_core_rmem_default }}
- net.core.wmem_default = {{ network_buffer_settings.net_core_wmem_default }}
- net.ipv4.tcp_rmem = {{ network_buffer_settings.net_ipv4_tcp_rmem }}
- net.ipv4.tcp_wmem = {{ network_buffer_settings.net_ipv4_tcp_wmem }}
- net.core.netdev_max_backlog = {{ network_buffer_settings.net_core_netdev_max_backlog }}
- net.ipv4.tcp_congestion_control = {{ network_buffer_settings.net_ipv4_tcp_congestion_control }}

===========================================
Storage I/O Scheduler Configuration
===========================================
I/O Queue Sorting: Enabled
ZFS vdev Cache Size: 10MB
ZFS Prefetching: Enabled
ZFS TXG Timeout: 5 seconds

Configuration Details:
- kern.cam.sort_io_queues = 1
- vfs.zfs.vdev.cache.size = 10485760
- vfs.zfs.prefetch_disable = 0
- vfs.zfs.txg.timeout = 5

===========================================
Performance Recommendations
===========================================
1. Monitor system memory usage to ensure ARC settings are appropriate
2. Verify CPU governor is suitable for your workload (performance vs power efficiency)
3. Adjust network buffer sizes based on network throughput requirements
4. Monitor ZFS pool performance and adjust cache settings if needed
5. Consider enabling compression on ZFS datasets for better I/O performance
6. Regular monitoring of system performance metrics is recommended

===========================================
Next Steps
===========================================
1. Reboot the system to apply all sysctl changes
2. Monitor system performance for 24-48 hours
3. Adjust settings based on actual workload patterns
4. Consider additional optimizations based on specific use cases

Note: All settings have been configured via TrueNAS API and will persist across reboots.
For any issues, check the TrueNAS System -> Tunables section in the web interface.